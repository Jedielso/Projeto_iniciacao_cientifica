# -*- coding: utf-8 -*-
"""Modelo 1 em 08/04/2024

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-2bhYMObnS40-gF_I0tQ0WKczMtHjeL4

# Segmentação Semântica em Imagens de Satélite para Identificação de Favelas e Comunidades Urbanas na Cidade do Rio de Janeiro

## Modelo 1

Este modelo utilizará exclusivamente as imagens originais já segmentadas. Foram segmentadas um total de 238 imagens nas Áreas de Planejamento 1, 2, 3 e 4.
Pasta no Google Drive com o conjunto de dados: https://drive.google.com/drive/folders/1wd6kdrwi1I_Wq9wwZXtV4Q1WAUXnAC4V?usp=drive_link

## Importando as bibliotecas
"""

# Bibliotecas
import os
import random
from glob import glob

import cv2
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
from imageio import mimread
from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.utils import shuffle
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau, CSVLogger
from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D, Conv2DTranspose, Dropout,
                                     Input, Lambda, MaxPool2D, MaxPooling2D, ReLU, UpSampling2D, concatenate)
from tensorflow.keras.metrics import MeanIoU, Precision, Recall
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import CustomObjectScope

from google.colab.patches import cv2_imshow
from tqdm import tqdm

print(tf.__version__)

# Semente
seed = 2024
np.random.seed = seed
random.seed = seed
tf.random.set_seed(2024)

"""## Conectando com o Google Drive"""

# Conectando com o Google Drive
from google.colab import drive
drive.mount('/content/gdrive')

# Copiando a pasta TCC do Google Drive para o Google Colab
!cp -R /content/gdrive/MyDrive/TCC/ TCC

"""## Visualizando algumas imagens e suas respectivas máscaras"""

def exibir_imagens_e_mascaras(pasta_imagens, pasta_mascaras, quantidade=6):
    # Lista de arquivos na pasta de imagens
    arquivos_imagens = os.listdir(pasta_imagens)[:quantidade]

    # Exibir cada imagem e sua máscara correspondente
    for imagem in arquivos_imagens:
        # Caminho da imagem e sua máscara correspondente
        caminho_imagem = os.path.join(pasta_imagens, imagem)
        caminho_mascara = os.path.join(pasta_mascaras, imagem)

        # Carregar imagem e máscara
        img = cv2.imread(caminho_imagem)
        mask = cv2.imread(caminho_mascara)

        # Remover extensão .png do nome da imagem
        nome_imagem = os.path.splitext(imagem)[0]

        # Exibir imagem e máscara
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f'Imagem {nome_imagem}')
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))
        plt.title(f'Máscara {nome_imagem}')
        plt.axis('off')

        plt.show()

# Exibir as 6 primeiras imagens e máscaras da pasta 'imagens/treino' e 'mascaras/treino'
exibir_imagens_e_mascaras('/content/TCC/imagens/treino', '/content/TCC/mascaras/treino', quantidade=6)

"""## Carregando as imagens de treino e teste"""

# Função para carregar os dados
def dataset_modelo1(caminho):
  img_treino = sorted(glob(os.path.join(caminho, "imagens", "treino", "*.png")))
  masc_treino = sorted(glob(os.path.join(caminho, "mascaras", "treino", "*.png")))

  img_teste = sorted(glob(os.path.join(caminho, "imagens", "teste", "*.png")))
  masc_teste = sorted(glob(os.path.join(caminho, "mascaras", "teste", "*.png")))

  return (img_treino, masc_treino), (img_teste, masc_teste)

pasta = "TCC"
(img_treino, masc_treino), (img_teste, masc_teste) = dataset_modelo1(pasta)

# Tamanho do subset de treino e teste
len(img_treino), len(masc_treino), len(img_teste), len(masc_teste)

# Tamanho das imagens
img_altura = 512
img_largura = 512

"""## Construção da Rede Neural - U-Net"""

def bloco_conv(input, num_filters):
    x = Conv2D(num_filters, 3, padding="same")(input)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)

    x = Conv2D(num_filters, 3, padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)

    return x

def bloco_encoder(input, num_filters):
    x = bloco_conv(input, num_filters)
    p = MaxPool2D((2, 2))(x)
    return x, p


def bloco_decoder(input, skip_features, num_filters):
    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding="same")(input)
    x = Concatenate()([x, skip_features])
    x = bloco_conv(x, num_filters)
    return x


def modelo_unet(input_shape):
    inputs = Input(input_shape)

    s1, p1 = bloco_encoder(inputs, 64)
    s2, p2 = bloco_encoder(p1, 64*2) #128
    s3, p3 = bloco_encoder(p2, 64*4) #256
    s4, p4 = bloco_encoder(p3, 64*8) #512

    b1 = bloco_conv(p4, 64*16)  #1024

    d1 = bloco_decoder(b1, s4, 64*8) #512
    d2 = bloco_decoder(d1, s3, 64*4) #256
    d3 = bloco_decoder(d2, s2, 64*2) #128
    d4 = bloco_decoder(d3, s1, 64)

    outputs = Conv2D(1, 1, padding="same", activation="sigmoid")(d4)

    model = Model(inputs, outputs, name="UNet")
    return model

# Métricas
""" IoU """
def iou(y_true, y_pred, smooth=1):
    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])
    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection
    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)
    return iou

""" Dice Coefficient """
def dice_coef(y_true, y_pred, smooth=1):
    intersection = K.sum(y_true * y_pred, axis=[1,2,3])
    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])
    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)

""" Dice Coefficient Loss """
def dice_coef_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

# Hiperparâmetros
epochs = 50 # número de épocas
batch_size = 2 # tamanho do lote
lr = 1e-4 # taxa de aprendizado (0.0001)

# Criar o modelo UNet com as dimensões da entrada especificadas
model = modelo_unet((img_altura, img_largura, 3))

# Compilar o modelo usando a função de perda dice_coef_loss, o otimizador Adam e as métricas de avaliação
model.compile(loss=dice_coef_loss, optimizer=Adam(lr), metrics=[dice_coef, iou, 'accuracy'])

# Exibir um resumo do modelo, mostrando a arquitetura da rede neural e o número de parâmetros
model.summary()

"""## Pré-processamento e criação de conjunto de dados usando TensorFlow"""

# Função para ler e pré-processar uma imagem do dataset
def ler_img_dataset(caminho):
    # Decodificar o caminho
    caminho = caminho.decode()
    # Ler a imagem
    img = cv2.imread(caminho)
    # Normalizar os valores dos pixels para o intervalo [0, 1]
    img = img / 255.0
    # Converter os pixels para o tipo de dado float32
    img = img.astype(np.float32)
    return img

# Função para ler e pré-processar uma máscara do dataset
def ler_mask_dataset(caminho):
    # Decodificar o caminho
    caminho = caminho.decode()
    # Ler a máscara em escala de cinza
    img = cv2.imread(caminho, cv2.IMREAD_GRAYSCALE)
    # Normalizar os valores dos pixels para o intervalo [0, 1]
    img = img / 255.0
    # Converter os pixels para o tipo de dado float32
    img = img.astype(np.float32)
    # Adicionar uma dimensão de canal para a máscara
    img = np.expand_dims(img, axis=-1) # (512, 512) -> (512, 512, 1)
    return img

# Função para processar um par de imagem e máscara usando TensorFlow
def tf_parse(x, y):
    def _parse(x, y):
        # Ler e pré-processar a imagem
        x = ler_img_dataset(x)
        # Ler e pré-processar a máscara
        y = ler_mask_dataset(y)
        return x, y

    # Aplicar a função de pré-processamento usando numpy_function
    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])
    # Definir a forma das imagens e máscaras
    x.set_shape([img_altura, img_largura, 3])
    y.set_shape([img_altura, img_largura, 1])
    return x, y

# Função para criar um TensorFlow dataset a partir de imagens e máscaras
def tf_dataset(X, y, batch_size=2):
    # Criar um dataset a partir dos arrays de entrada
    dataset = tf.data.Dataset.from_tensor_slices((X, y))
    # Aplicar a função de processamento em paralelo
    dataset = dataset.map(tf_parse)
    # Agrupar os dados em lotes
    dataset = dataset.batch(batch_size)
    # Pré-carregar dados para otimizar o carregamento
    dataset = dataset.prefetch(4)
    return dataset

# Função para embaralhar os dados de treinamento
def embaralha(x, y, seed=2024):
    # Embaralhar os arrays de entrada
    x, y = shuffle(x, y, random_state=seed)
    return x, y

# Embaralhar os dados de treinamento
img_treino, masc_treino = embaralha(img_treino, masc_treino)

# Exibe o índice e o nome do arquivo
for indice, nome in enumerate(img_treino):
    nome_arquivo = os.path.basename(nome)
    print(f"Índice: {indice}, Nome do Arquivo: {nome_arquivo}")

# Criar datasets de treinamento e teste usando TensorFlow
dataset_treino = tf_dataset(img_treino, masc_treino, batch_size=batch_size)
dataset_teste = tf_dataset(img_teste, masc_teste, batch_size=batch_size)

"""## Treinamento"""

# Função para criar um diretório se ele não existir
def criar_diretorio(caminho):
    # Verifica se o diretório não existe
    if not os.path.exists(caminho):
        # Cria o diretório
        os.makedirs(caminho)

path_modelo = 'modelo'
criar_diretorio(path_modelo)

# Lista de callbacks a serem utilizados durante o treinamento do modelo
callbacks = [
    # ModelCheckpoint: Salva o modelo a cada época no formato especificado, se for o melhor modelo até o momento
    ModelCheckpoint(path_modelo + '/modelo_drive_{epoch:02d}.h5', verbose=1, save_best_only=True),
]

# Treinamento do modelo utilizando os dados de treino e validação
history = model.fit(dataset_treino, epochs=epochs, validation_data=dataset_teste, callbacks=callbacks)

# Métricas
history.history.keys()

# Função para exibir gráficos de métricas de treinamento e validação ao longo das épocas
def mostrar_graficos(history):
    # Configuração da figura para os gráficos
    fig = plt.gcf()
    fig.set_size_inches(16, 4)

    # Gráfico de Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], 'red', label='Accuracy treinamento')
    plt.plot(history.history['val_accuracy'], 'blue', label='Accuracy validação')
    plt.legend()
    plt.title('Accuracy')

    # Gráfico de Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], 'red', label='Loss treinamento')
    plt.plot(history.history['val_loss'], 'blue', label='Loss validação')
    plt.legend()
    plt.title('Loss')

    # Exibir os gráficos
    plt.show()

mostrar_graficos(history)

def extrair_metricas(history):
    # Criar DataFrame das métricas
    metrics_df = pd.DataFrame({
        'accuracy_treinamento': history.history['accuracy'],
        'accuracy_validacao': history.history['val_accuracy'],
        'loss_treinamento': history.history['loss'],
        'loss_validacao': history.history['val_loss']
    })

    return metrics_df

# Exibir métricas
metrics_dataframe = extrair_metricas(history)
print(metrics_dataframe)

# # Definir o caminho para salvar o arquivo Excel na pasta TCC do Google Drive
# caminho_arquivo_excel = '/content/gdrive/MyDrive/TCC/metricas.xlsx'

# # Salvar o DataFrame em um arquivo Excel
# metrics_dataframe.to_excel(caminho_arquivo_excel)

"""### Salvando o melhor modelo"""

# Copiando o modelo treinado para o Google Drive
!cp /content/modelo/modelo_drive_39.h5 /content/gdrive/MyDrive/TCC/modelos/

# Copiando o modelo treinado para o Google Drive
!cp /content/modelo/modelo_drive_36.h5 /content/gdrive/MyDrive/TCC/modelos/

"""### Carregando o melhor modelo"""

# Utilização do contexto CustomObjectScope para fornecer as funções personalizadas 'iou', 'dice_coef' e 'dice_coef_loss' durante o carregamento do modelo
with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_coef_loss': dice_coef_loss}):
    # Carregamento do modelo treinado utilizando a função load_model, fornecendo o caminho do arquivo h5 do modelo
    modelo_teste = load_model('/content/modelo/modelo_drive_39.h5')

# Carrega os pesos do modelo previamente treinado a partir do arquivo h5 especificado
modelo_teste.load_weights('/content/modelo/modelo_drive_39.h5')

"""## Teste do Modelo"""

# Função para ler uma imagem a partir do caminho especificado
def ler_img(caminho):
    # Lê a imagem usando OpenCV, mantendo-a no formato BGR
    img = cv2.imread(caminho, cv2.IMREAD_COLOR)
    # Faz uma cópia da imagem original
    img_original = img.copy()
    # Normaliza os valores dos pixels para o intervalo [0, 1]
    img = img / 255.0
    # Converte os valores dos pixels para o tipo float32
    img = img.astype(np.float32)
    # Retorna a imagem normalizada e a imagem original
    return img, img_original

# Função para ler uma máscara a partir do caminho especificado
def ler_mascara(caminho):
    # Lê a máscara em escala de cinza usando OpenCV
    img = cv2.imread(caminho, cv2.IMREAD_GRAYSCALE)
    # Armazena uma cópia da máscara original
    img_original = img
    # Normaliza os valores dos pixels para o intervalo [0, 1]
    img = img / 255.0
    # Converte os valores dos pixels para o tipo int32
    img = img.astype(np.int32)
    # Retorna a máscara normalizada e a máscara original
    return img, img_original

# Função para segmentar uma imagem usando um modelo de segmentação fornecido
def segmenta_img(img, modelo_teste):
    # Realiza a predição da imagem usando o modelo fornecido
    predicao = modelo_teste.predict(np.expand_dims(img, axis=0))[0]
    # Converte as probabilidades em máscaras binárias com base em um limiar de 0.5
    predicao = predicao > 0.5
    # Converte os valores booleanos para inteiros (0 ou 1)
    predicao = predicao.astype(np.int32)
    # Remove a dimensão de profundidade da máscara resultante
    predicao = np.squeeze(predicao, axis=-1)
    # Retorna a máscara segmentada
    return predicao

# Tamanho do subset de teste
len(img_teste), len(masc_teste)

# Exibe o índice e o nome do arquivo
for indice, nome in enumerate(img_teste):
    nome_arquivo = os.path.basename(nome)
    print(f"Índice: {indice}, Nome do Arquivo: {nome_arquivo}")

# Seleciona aleatoriamente 48 índices únicos da lista de índices de imagens de teste
lista_teste = np.random.choice(len(img_teste), 48, replace=False)
lista_teste

# Itera sobre os índices de imagens de teste selecionados aleatoriamente
for id_img in lista_teste:
    # Carrega a imagem e sua versão original
    img, img_original = ler_img(img_teste[id_img])

    # Carrega a máscara e sua versão original
    mask, mask_original = ler_mascara(masc_teste[id_img])

    # Realiza a segmentação da imagem usando o modelo previamente treinado
    predicao = segmenta_img(img, modelo_teste)

    # Extrai o número da imagem removendo a extensão (.png)
    num_imagem = os.path.basename(img_teste[id_img]).replace('.png', '')

    # Cria uma figura para exibir as imagens e suas predições
    fig = plt.figure(figsize=(16, 8))

    # Adiciona o subplot da imagem original
    fig.add_subplot(1,3,1)
    plt.imshow(cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.title(f"Imagem - {num_imagem}")

    # Adiciona o subplot da máscara original (ground truth)
    plt.subplot(1,3,2)
    plt.imshow(mask_original, cmap="gray")
    plt.axis("off")
    plt.title(f"Máscara - {num_imagem}")

    # Adiciona o subplot da predição gerada pelo modelo
    plt.subplot(1,3,3)
    plt.imshow(predicao, cmap="gray")
    plt.axis("off")
    plt.title(f"Predição (U-Net) - {num_imagem}")

    # Exibir a figura
    plt.show()

# Define a cor do fundo como preto no formato BGR
cor_do_fundo = (0, 0, 0)

# Define o tamanho da figura que conterá as imagens
plt.figure(figsize=(24, 92))

# Define o número de linhas e colunas para organizar as imagens na figura
num_linhas = 12
num_colunas = 4

# Define o espaçamento entre os subplots
plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, hspace=0.05, wspace=0.05)

# Itera sobre as imagens de teste
for id_img in range(48):
    # Carrega a imagem original e sua máscara correspondente
    img, img_original = ler_img(img_teste[id_img])
    mask, mask_original = ler_mascara(masc_teste[id_img])

    # Realiza a segmentação da imagem
    predicao = segmenta_img(img, modelo_teste)

    # Combina a imagem original com a máscara de predição
    altura, largura = img.shape[:2]
    fundo_branco = 255 * np.ones((altura, largura, 3), dtype='uint8')
    img_final = img_original.copy()
    img_final[predicao == 0] = fundo_branco[predicao == 0]

    # Define a cor do fundo após combinar as imagens
    img_final[np.all(img_final == [255, 255, 255], axis=-1)] = cor_do_fundo

    # Extrai o nome do arquivo da imagem removendo a extensão (.png)
    nome_imagem = os.path.basename(img_teste[id_img]).replace('.png', '')

    # Plota a imagem final na posição correspondente da grade
    plt.subplot(num_linhas, num_colunas, id_img + 1)
    plt.imshow(cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB))
    plt.title(f'Imagem - {nome_imagem}')  # Define o título da imagem com o nome do arquivo
    plt.axis('off')  # Remove os eixos

# Exibe a figura contendo as imagens
plt.show()

lista_scores = []

# Iteração sobre as imagens de teste e suas respectivas máscaras
for x, y in tqdm(zip(img_teste, masc_teste), total=len(img_teste)):
    # Extrai o nome da imagem
    nome = os.path.basename(x).split(".")[0]

    # Carrega a imagem e sua máscara
    img, img_original = ler_img(x)
    mask, mask_original = ler_mascara(y)

    # Gera a predição da máscara
    predicao = segmenta_img(img, modelo_teste)

    # Transforma as máscaras em arrays unidimensionais
    mask_ = mask.flatten()
    pred_ = predicao.flatten()

    # Calcula as métricas precision, recall, F1 e support
    precision, recall, f1, _ = precision_recall_fscore_support(mask_, pred_, average='binary')

    # Calcula o valor de IoU entre a máscara original e a predição
    IoU_resultado = MeanIoU(num_classes=2)
    IoU_resultado.update_state(mask, predicao)
    valor_iou = IoU_resultado.result().numpy()

    # Calcula a acurácia entre a máscara original e a predição
    valor_acc = accuracy_score(mask_, pred_)

    # Adiciona os resultados à lista de scores
    lista_scores.append([nome, valor_iou, valor_acc, precision, recall, f1])

# Calcula as médias dos scores de IoU, Accuracy, Precision, Recall e F1
medias_score = np.mean([s[1:] for s in lista_scores], axis=0)

# Exibe as médias de IoU, Accuracy, Precision, Recall e F1
print(f"\nMédia do IoU: {medias_score[0]:0.5f}")
print(f"Média do Accuracy: {medias_score[1]:0.5f}")
print(f"Média do Precision: {medias_score[2]:0.5f}")
print(f"Média do Recall: {medias_score[3]:0.5f}")
print(f"Média do F1: {medias_score[4]:0.5f}")

# Criando o DataFrame com os scores de IoU, Accuracy, Precision, Recall e F1
dados_scores = pd.DataFrame(lista_scores, columns=['Imagem', 'IoU', 'Accuracy', 'Precision', 'Recall', 'F1'])

# Salvando o DataFrame em um arquivo Excel na pasta TCC do Google Drive
caminho_arquivo_excel = '/content/gdrive/MyDrive/TCC/dados_scores_modelo1_08_de_abril.xlsx'
dados_scores.to_excel(caminho_arquivo_excel, index=False)
